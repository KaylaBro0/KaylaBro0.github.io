---
layout: post  
title: "Day 24 â€“ Fixing the Reward Bug in Rainbow DQN ðŸ™ƒ"  
date: 2025-06-27  
author: Mikayla Brown  
permalink: /day24.html  
tags: ["Rainbow DQN", "Reinforcement Learning", "Model Tuning"]

what_i_learned: |
 Today I made some big improvements to the Rainbow DQN model. I realized that the reason it was performing so "well" before was because it had 
 learned to do nothing and still get rewarded. Basically, the model figured out that inaction gave it good results, which obviously isnâ€™t the 
 behavior we want.I went in and adjusted the reward structure so that doing nothing wouldnâ€™t be seen as the best option. I also worked on
 integrating the other biochemical parameters like creatinine, potassium, sodium, and GPTâ€”into the model. It was a bit of a struggle to get  
 everything working smoothly, but it's finally learning properly now.

blockers: |
 It was challenging to get the model to stop rewarding inaction and actually learn from the environment. Also had to deal with some integration 
 issues when adding the new biochemical parameters.

reflection: |
 The model is sitting at about 50% accuracy now, which I think is pretty solid progress. The average reward is at 100%, so we're in a strong  
 learning position. Today was a reminder that good performance metrics donâ€™t always mean good behavior sometimes the model is just being clever 
 in the wrong way.
---

